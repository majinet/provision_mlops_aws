name: Step 3 - Provisioning EFS for Kubeflow

on:
  workflow_dispatch:
    inputs:
      region:
        description: 'AWS Region'
        required: true
        default: 'us-east-1'
      #keypair:
      #  description: 'SSH Key Pair'
      #  required: true

env:
  AWS_REGION : ${{ github.event.inputs.region}} #Change to reflect your Region
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  CLUSTER_NAME: 'eks-cluster'

# Permission can be added at job level or workflow level
permissions:
      id-token: write   # This is required for requesting the JWT
      contents: read    # This is required for actions/checkout

jobs:
  efs_aws:
    name: Provisioning EFS
    runs-on: ubuntu-latest
    outputs:
      env-name: ${{ steps.env-name.outputs.environment }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Checkout awslabs kubeflow-manifests
        uses: actions/checkout@v3
        with:
          repository: awslabs/kubeflow-manifests
          ref: v1.7.0-aws-b1.0.2
          path: kubeflow-manifests
      - name: Configure AWS credentials
        id: creds
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::${{secrets.AWS_ACCOUNT_ID}}:role/KubeAdmin
          role-session-name: KubeAdmin
          aws-region: ${{ github.event.inputs.region}}
      - name: Configure environment name
        id: env-name
        env:
          REPO: ${{ github.repository }}
        run: |
          ENVIRONMENT=`echo $REPO | tr "/" "-"`
          echo "Environment name: $ENVIRONMENT"
          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
      #- name: Allow passwordless sudo
      #  run: echo '${{ secrets.SUDO_PASSWORD }}' | sudo -Sv
      - name: install envsubst
        id: install-envsubst
        run: |
          curl -L https://github.com/a8m/envsubst/releases/download/v1.2.0/envsubst-`uname -s`-`uname -m` -o envsubst
          chmod +x envsubst
          sudo mv envsubst /usr/local/bin
      - name: install eksctl
        id: install-eksctl
        run: |
          # for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
          ARCH=amd64
          PLATFORM=$(uname -s)_$ARCH

          curl -sLO "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
          tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
          sudo mv /tmp/eksctl /usr/local/bin
      - name: install kubectl
        id: install-kubectl
        run: |
          curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.27.1/2023-04-19/bin/linux/amd64/kubectl
          chmod +x ./kubectl
          mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH
          kubectl version --short --client
      - name: Health Check Cluster
        id: health-check-eks
        run: |
          aws eks update-kubeconfig --name ${{env.CLUSTER_NAME}} --region ${{env.AWS_REGION}}
          kubectl config get-contexts

          # Ensure cluster has compute
          kubectl get nodes
      - name: Install the EFS CSI driver
        id: install-efs-csi-driver
        run: |
          kubectl apply -k "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=tags/v1.5.4"
          kubectl get csidriver
      - name: Set VPC ID
        id: set-vpc-id
        run: |
          VPC_ID=$(aws eks describe-cluster \
                    --name ${{env.CLUSTER_NAME}} \
                    --query "cluster.resourcesVpcConfig.vpcId" \
                    --output text)
          echo "VPC ID: $VPC_ID"
          echo "VPC_ID=$VPC_ID" >> $GITHUB_ENV
      - name: Set CIDR range
        id: set-CIDR
        run: |
          cidr_range=$(aws ec2 describe-vpcs \
              --vpc-ids ${{env.VPC_ID}} \
              --query "Vpcs[].CidrBlock" \
              --output text \
              --region ${{env.AWS_REGION}})
          
          echo "CIDR_RANGE: $cidr_range"
          echo "CIDR_RANGE=$cidr_range" >> $GITHUB_ENV
      - name: Set Subnet ID for EFS
        id: set-subnet-id
        run: |
          subnet_ids=$(aws cloudformation describe-stacks --stack-name eksctl-eks-cluster-cluster --query 'Stacks[0].Outputs[?OutputKey==`SubnetsPrivate`].OutputValue' --output text)
          IFS=", " read -r var1 var2  var3 <<< "$subnet_ids"
          
          echo "SUBNET_ID_1: $var1"
          echo "SUBNET_ID_1=$var1" >> $GITHUB_ENV
          
          echo "SUBNET_ID_2: $var2"
          echo "SUBNET_ID_2=$var2" >> $GITHUB_ENV
          
          echo "SUBNET_ID_3: $var3"
          echo "SUBNET_ID_3=$var3" >> $GITHUB_ENV
      - name: check security group if exists
        id: check-security-group
        run: |
          security_group_id=$(aws ec2 describe-security-groups --filters Name=vpc-id,Values=${{env.VPC_ID}} Name=group-name,Values=MyEfsSecurityGroup --query 'SecurityGroups[0].GroupId' --output text)
          
          if [[ $security_group_id == 'None' ]]; then
            echo "IAM Service Account does not exist."
            echo "::set-output name=exists::false"
          else
            echo "IAM Service Account exists."
            echo "::set-output name=exists::true"
          
            echo "SECURITY_GROUP_ID: $security_group_id"
            echo "SECURITY_GROUP_ID=$security_group_id" >> $GITHUB_ENV
          fi
      - name: Create security group with an inbound
        id: create-sg-inbound
        if: steps.check-security-group.outputs.exists == 'false'
        run: |
          security_group_id=$(aws ec2 create-security-group \
              --group-name MyEfsSecurityGroup \
              --description "My EFS security group" \
              --vpc-id ${{env.VPC_ID}} \
              --output text)
          
          aws ec2 authorize-security-group-ingress \
              --group-id $security_group_id \
              --protocol tcp \
              --port 2049 \
              --cidr ${{env.CIDR_RANGE}}
          
          echo "SECURITY_GROUP_ID: $security_group_id"
          echo "SECURITY_GROUP_ID=$security_group_id" >> $GITHUB_ENV
      - name: check efs if exists
        id: check-efs
        run: |
          file_system_id=$(aws efs describe-file-systems --query "FileSystems[0].FileSystemId" --output text)
          
          if [[ "$file_system_id" == fs* ]]; then
            echo "EFS exists. Skipping next step..."
            echo "::set-output name=exists::true"
          else
            echo "EFS does not exists."
            echo "::set-output name=exists::false"
          fi
          
          echo "FILE_SYSTEM_ID: $file_system_id"
          echo "FILE_SYSTEM_ID=$file_system_id" >> $GITHUB_ENV
      - name: Create an Amazon EFS file system
        id: create-aws-efs
        if: steps.check-efs.outputs.exists == 'false'
        run: |        
          # Create a file system
          file_system_id=$(aws efs create-file-system \
              --region ${{env.AWS_REGION}} \
              --performance-mode generalPurpose \
              --query 'FileSystemId' \
              --output text)
          
          echo "FILE_SYSTEM_ID: $file_system_id"
          echo "FILE_SYSTEM_ID=$file_system_id" >> $GITHUB_ENV
      - name: Mount efs to node
        id: mount-efs
        if: steps.check-efs.outputs.exists == 'false'
        run: |
          # Add mount targets Notes: this will return failed and require execute command manually.
          aws efs create-mount-target \
              --file-system-id ${{env.FILE_SYSTEM_ID}} \
              --subnet-id ${{env.SUBNET_ID_1}} \
              --security-groups ${{env.SECURITY_GROUP_ID}}
          aws efs create-mount-target \
              --file-system-id ${{env.FILE_SYSTEM_ID}} \
              --subnet-id ${{env.SUBNET_ID_2}} \
              --security-groups ${{env.SECURITY_GROUP_ID}}
          aws efs create-mount-target \
              --file-system-id ${{env.FILE_SYSTEM_ID}} \
              --subnet-id ${{env.SUBNET_ID_3}} \
              --security-groups ${{env.SECURITY_GROUP_ID}}
        continue-on-error: true
      #- name: Create dynamic provisioning of storage class
      #  id: create-dynamic-sc
      #  run: |
      #    export GITHUB_STORAGE_DIR="deployments/add-ons/storage/"
      #    export PVC_NAMESPACE=kubeflow-user-example-com #testenv
      #    export CLAIM_NAME=efs-claim #efs-test-claim

      #    cd kubeflow-manifests
      #    export file_system_id=${{env.FILE_SYSTEM_ID}}
      #    file_system_id=$file_system_id yq e '.parameters.fileSystemId = env(file_system_id)' -i $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/sc.yaml
      #    kubectl apply -f $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/sc.yaml
          
      #    yq e '.metadata.namespace = env(PVC_NAMESPACE)' -i $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/pvc.yaml
      #    yq e '.metadata.name = env(CLAIM_NAME)' -i $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/pvc.yaml
      #    kubectl apply -f $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/pvc.yaml
      - name: create storage class
        run: |
          export GITHUB_STORAGE_DIR="deployments/add-ons/storage/"
          export file_system_id=${{env.FILE_SYSTEM_ID}}
          
          cd kubeflow-manifests
          
          yq e '.parameters.fileSystemId = env(file_system_id)' -i $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/sc.yaml
          kubectl apply -f $GITHUB_STORAGE_DIR/efs/dynamic-provisioning/sc.yaml
      - name: change efs storage class to default
        id: change-default-efs-sc
        run: |
          kubectl patch storageclass gp2 -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
          kubectl patch storageclass efs-sc -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
      #- name: set permission in notebook
      #  run: |
      #    export GITHUB_STORAGE_DIR="deployments/add-ons/storage/"
      #    export PVC_NAMESPACE=testenv
      #    export CLAIM_NAME=efs-test-claim
          
      #    cd kubeflow-manifests
      #    yq e '.metadata.name = env(CLAIM_NAME)' -i $GITHUB_STORAGE_DIR/notebook-sample/set-permission-job.yaml
      #    yq e '.metadata.namespace = env(PVC_NAMESPACE)' -i $GITHUB_STORAGE_DIR/notebook-sample/set-permission-job.yaml
      #    yq e '.spec.template.spec.volumes[0].persistentVolumeClaim.claimName = env(CLAIM_NAME)' -i $GITHUB_STORAGE_DIR/notebook-sample/set-permission-job.yaml

      #    kubectl apply -f $GITHUB_STORAGE_DIR/notebook-sample/set-permission-job.yaml







